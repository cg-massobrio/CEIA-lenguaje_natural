{"cells":[{"cell_type":"markdown","metadata":{"id":"Ue5hxxkdAQJg"},"source":["<img src=\"https://github.com/FIUBA-Posgrado-Inteligencia-Artificial/procesamiento_lenguaje_natural/raw/main/logoFIUBA.jpg\" width=\"500\" align=\"center\">\n","\n","\n","# Procesamiento de lenguaje natural\n","## Word2vect\n"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"kCED1hh-Ioyf"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","from collections import Counter"]},{"cell_type":"markdown","metadata":{"id":"DMOa4JPSCJ29"},"source":["### Datos"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"RIO7b8GjAC17"},"outputs":[],"source":["corpus = np.array(['que dia es hoy', 'martes el dia de hoy es martes', 'martes muchas gracias'])"]},{"cell_type":"markdown","metadata":{"id":"8WqdaTmO8P1r"},"source":["Documento 1 --> que dia es hoy \\\n","Documento 2 --> martes el dia de hoy es martes \\\n","Documento 3 --> martes muchas gracias"]},{"cell_type":"markdown","metadata":{"id":"FVHxBRNzCMOS"},"source":["### 1 - Obtener el vocabulario del corpus (los términos utilizados)\n","- Cada documento transformarlo en una lista de términos\n","- Armar un vector de términos no repetidos de todos los documentos"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["# Función para armar el diccionario con los documentos y el vocabulario del corpus\n","def doc_voc(corpus):\n","    '''\n","    corpus: corpus que contiene todas las sentencias del texto.\n","    '''\n","    # Inicialización de variables\n","    terms = {}\n","    vocabulary = np.empty(0)\n","\n","    # Diccionario con los documentos del corpus\n","    for k, v in enumerate(corpus):\n","        terms[k] = corpus[k].split(' ')\n","    \n","    # Vocabulario del corpus\n","    for key in terms.keys(): \n","        vocabulary = np.concatenate((vocabulary, np.array(terms[key])), axis=None)\n","    \n","    return terms, np.unique(vocabulary)\n"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Documento 0: ['que', 'dia', 'es', 'hoy']\n","Documento 1: ['martes', 'el', 'dia', 'de', 'hoy', 'es', 'martes']\n","Documento 2: ['martes', 'muchas', 'gracias']\n","Array con el vocabulario del corpus: ['de' 'dia' 'el' 'es' 'gracias' 'hoy' 'martes' 'muchas' 'que']\n","Cantidad de términos que contine el vocabulario: 9\n"]}],"source":["# Impresión de documentos y vocabulario del corpus\n","terms, vocabulary = doc_voc(corpus)\n","\n","for i in range(len(terms)):\n","    print(f'Documento {i}: {terms[i]}')\n","\n","print(f'Array con el vocabulario del corpus: {doc_voc(corpus)[1]}')\n","print(f'Cantidad de términos que contine el vocabulario: {len(doc_voc(corpus)[1])}')"]},{"cell_type":"markdown","metadata":{"id":"RUhH983FI7It"},"source":["### 2- OneHot encoding\n","Dada una lista de textos, devolver una matriz con la representación oneHotEncoding de estos"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"Os0AAQo6I6Z1"},"outputs":[],"source":["# Función para contruir la matriz One Hot Encoding\n","def ohe(corpus):\n","    '''\n","    corpus: corpus que contiene todas las sentencias del texto.\n","    '''\n","\n","    # Definición de variables\n","    terms, vocabulary = doc_voc(corpus)\n","    ohe = np.empty((0,len(vocabulary)), int)\n","\n","    # Armado de la matriz\n","    for key in terms.keys():\n","        l = np.isin(vocabulary, terms[key])\n","        ohe = np.vstack((ohe, l))\n","    return ohe"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Matriz representativa OHE: \n"," [[0 1 0 1 0 1 0 0 1]\n"," [1 1 1 1 0 1 1 0 0]\n"," [0 0 0 0 1 0 1 1 0]]\n"]}],"source":["OHE = ohe(corpus)\n","print(f'Matriz representativa OHE: \\n {OHE}')"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>de</th>\n","      <th>dia</th>\n","      <th>el</th>\n","      <th>es</th>\n","      <th>gracias</th>\n","      <th>hoy</th>\n","      <th>martes</th>\n","      <th>muchas</th>\n","      <th>que</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>doc 1</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>doc 2</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>doc 3</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       de  dia  el  es  gracias  hoy  martes  muchas  que\n","doc 1   0    1   0   1        0    1       0       0    1\n","doc 2   1    1   1   1        0    1       1       0    0\n","doc 3   0    0   0   0        1    0       1       1    0"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["# Preparación de una mejor visualización del encoding OHE\n","idx = ['doc 1', 'doc 2', 'doc 3'] \n","df_ohe = pd.DataFrame(ohe(corpus), columns=vocabulary, index=idx)\n","df_ohe"]},{"cell_type":"markdown","metadata":{"id":"IIyWGmCpJVQL"},"source":["### 3- Vectores de frecuencia\n","Dada una lista de textos, devolver una matriz con la representación de frecuencia de estos"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["# Función para contruir la matriz Frecuency Array\n","\n","def fa(corpus):\n","    '''\n","    corpus: corpus que contiene todas las sentencias del texto.\n","    '''\n","\n","    # Definición de variables\n","    terms, vocabulary = doc_voc(corpus)\n","    fa = np.empty((0,len(vocabulary)), int)\n","\n","    # Armado de la matriz\n","    for key in terms.keys():\n","        r = Counter(terms[key])\n","        l = np.isin(vocabulary, terms[key]).astype(int)\n","        for i in range(len(l)): \n","            if l[i] == 1:\n","                l[i] = r[vocabulary[i]]\n","            else:\n","                l[i] = 0\n","        fa = np.vstack((fa, l))\n","    return fa"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Matriz representativa Frecuency Array: \n"," [[0 1 0 1 0 1 0 0 1]\n"," [1 1 1 1 0 1 2 0 0]\n"," [0 0 0 0 1 0 1 1 0]]\n"]}],"source":["FA = fa(corpus)\n","print(f'Matriz representativa Frecuency Array: \\n {fa(corpus)}')  "]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>de</th>\n","      <th>dia</th>\n","      <th>el</th>\n","      <th>es</th>\n","      <th>gracias</th>\n","      <th>hoy</th>\n","      <th>martes</th>\n","      <th>muchas</th>\n","      <th>que</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>doc 1</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>doc 2</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>doc 3</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       de  dia  el  es  gracias  hoy  martes  muchas  que\n","doc 1   0    1   0   1        0    1       0       0    1\n","doc 2   1    1   1   1        0    1       2       0    0\n","doc 3   0    0   0   0        1    0       1       1    0"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["# Preparación de una mejor visualización del encoding Frecuency Array \n","df_fa = pd.DataFrame(fa(corpus), columns=vocabulary, index=idx)\n","df_fa"]},{"cell_type":"markdown","metadata":{"id":"z_Ot8HvWJcBu"},"source":["### 4- TF-IDF\n","Data una lista de textos, devolver una matriz con la representacion TFIDF"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"waG_oWtpJjRw"},"outputs":[],"source":["# Función para armar la matriz TF|IDF\n","def tf_idf(corpus):\n","    '''\n","    corpus: corpus que contiene todas las sentencias del texto.\n","    '''\n","    # Definición de variables\n","    terms, vocabulary = doc_voc(corpus)\n","    ohe = np.empty((0,len(vocabulary)), int)\n","    fa = np.empty((0,len(vocabulary)), int)\n","\n","    # Armado de la matriz OHE\n","    for key in terms.keys():\n","        l = np.isin(vocabulary, terms[key])\n","        ohe = np.vstack((ohe, l))\n","\n","    # Armado de la matriz Frecuency Array\n","    for key in terms.keys():\n","        r = Counter(terms[key])\n","        l = np.isin(vocabulary, terms[key]).astype(int)\n","        for i in range(len(l)): \n","            if l[i] == 1:\n","                l[i] = r[vocabulary[i]]\n","            else:\n","                l[i] = 0\n","        fa = np.vstack((fa, l))\n","    \n","    # Factor IDF\n","    DF = np.sum(ohe, axis=0) # número total de documentos en la colección\n","    N = len(terms) # número de documentos en los que aparece un término del vocabulario\n","    mask = np.log10(N/DF) \n","\n","    # Matriz TF|IDF\n","    return fa*mask # la matriz Term Frecuency es la misma que se calculó en el punto anterior como \"fa\"\n"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Matriz representativa TF|IDF: \n"," [[0.         0.17609126 0.         0.17609126 0.         0.17609126\n","  0.         0.         0.47712125]\n"," [0.47712125 0.17609126 0.47712125 0.17609126 0.         0.17609126\n","  0.35218252 0.         0.        ]\n"," [0.         0.         0.         0.         0.47712125 0.\n","  0.17609126 0.47712125 0.        ]]\n"]}],"source":["TF_IDF = tf_idf(corpus)\n","print(f'Matriz representativa TF|IDF: \\n {TF_IDF}')  "]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>de</th>\n","      <th>dia</th>\n","      <th>el</th>\n","      <th>es</th>\n","      <th>gracias</th>\n","      <th>hoy</th>\n","      <th>martes</th>\n","      <th>muchas</th>\n","      <th>que</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>doc 1</th>\n","      <td>0.000000</td>\n","      <td>0.176091</td>\n","      <td>0.000000</td>\n","      <td>0.176091</td>\n","      <td>0.000000</td>\n","      <td>0.176091</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.477121</td>\n","    </tr>\n","    <tr>\n","      <th>doc 2</th>\n","      <td>0.477121</td>\n","      <td>0.176091</td>\n","      <td>0.477121</td>\n","      <td>0.176091</td>\n","      <td>0.000000</td>\n","      <td>0.176091</td>\n","      <td>0.352183</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>doc 3</th>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.477121</td>\n","      <td>0.000000</td>\n","      <td>0.176091</td>\n","      <td>0.477121</td>\n","      <td>0.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["             de       dia        el        es   gracias       hoy    martes  \\\n","doc 1  0.000000  0.176091  0.000000  0.176091  0.000000  0.176091  0.000000   \n","doc 2  0.477121  0.176091  0.477121  0.176091  0.000000  0.176091  0.352183   \n","doc 3  0.000000  0.000000  0.000000  0.000000  0.477121  0.000000  0.176091   \n","\n","         muchas       que  \n","doc 1  0.000000  0.477121  \n","doc 2  0.000000  0.000000  \n","doc 3  0.477121  0.000000  "]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["# Preparación de una mejor visualización de la matriz TF|IDF\n","df_TF_IDF = pd.DataFrame(TF_IDF, columns=vocabulary, index=idx)\n","df_TF_IDF"]},{"cell_type":"markdown","metadata":{"id":"xMcsfndWJjm_"},"source":["### 5 - Comparación de documentos\n","Realizar una funcion que reciba el corpus y el índice de un documento y devuelva los documentos ordenados por la similitud coseno"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["def simil_cos(corpus, d):\n","    '''\n","    Función que ordena los documentos del corpus por similitud coseno, a partir de un documento particular en el mismo.\n","    Devuelve un array cuya primer elemento es el documento a evaluar\n","\n","    La similitud coseno se práctica sobre la matriz TF|IDF\n","    - corpus: corpus que contiene todas las sentencias del texto.\n","    - d: número de documento el cual se quiere evaluar.\n","    '''\n","    \n","    # Matriz TF|IDF del corpus\n","    x = tf_idf(corpus)\n","    # Referencias de los documentos a comparar\n","    r_doc = np.delete(np.arange(0, len(x), 1), d)\n","    \n","    # Calculo de similitud coseno documento a documento y se acumula en una lista su valor\n","    score = []\n","    for j in range(len(r_doc)):\n","          coseno = np.dot(x[d,:],x[j,:])/((np.linalg.norm(x[d,:]))*(np.linalg.norm(x[j,:])))\n","          score.append(coseno)\n","    \n","    # Indice ordenando de mayor a menor los cálculos de similitud\n","    idx = np.argsort(score)[::-1]\n","    # Las referencias de los documentos se ajustan al ordenamiento de los cálculos de similitud\n","    r_doc_sort = r_doc[idx]\n","    # Se agrega como primer elemento el documento evaluado\n","    r_doc_sort=np.insert(r_doc_sort, 0, d)\n","\n","    # La función devuelve el corpus con los documentos ordenados según la similitud coseno y la referencia de los documentos\n","    return corpus[r_doc_sort], r_doc_sort\n","    "]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Documento de referencia 2: martes muchas gracias\n","Documento 1: martes el dia de hoy es martes\n","Documento 0: que dia es hoy\n"]}],"source":["d = 2\n","corpus_similitud, referencias = simil_cos(corpus, d)\n","\n","for i in range(len(referencias)):\n","    if i == 0:\n","        print(f'Documento de referencia {referencias[i]}: {corpus_similitud[i]}')\n","    else:\n","        print(f'Documento {referencias[i]}: {corpus_similitud[i]}')"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyO5fRYTpympAwJSVbric6dW","collapsed_sections":[],"name":"1a - word2vec.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3.9.7 ('base')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"vscode":{"interpreter":{"hash":"6bf44611de5320027ffcc509146da1c4e380cb2b0b6030fbe523cc5ad1f7c3e8"}}},"nbformat":4,"nbformat_minor":0}
